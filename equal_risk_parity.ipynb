{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04547812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acriddl2/Projects/.venv/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2026-02-02 12:18:59,140\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import sf_quant.data as sfd\n",
    "import sf_quant.optimizer as sfo\n",
    "import sf_quant.backtester as sfb\n",
    "import sf_quant.performance as sfp\n",
    "from sf_quant.data._factors import factors\n",
    "from sf_quant.data.covariance_matrix import _construct_factor_covariance_matrix\n",
    "import polars as pl\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "import time\n",
    "from time import perf_counter\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import LinearOperator\n",
    "from scipy.sparse.linalg import minres\n",
    "\n",
    "# start = dt.date(2023, 1, 1)\n",
    "# end = dt.date(2024, 1, 31)\n",
    "\n",
    "columns = [\n",
    "    'date',\n",
    "    'barrid',\n",
    "    'ticker',\n",
    "    'price',\n",
    "    'return',\n",
    "    'specific_risk',\n",
    "    'predicted_beta'\n",
    "]\n",
    "\n",
    "# data = sfd.load_assets(\n",
    "#     start=start,\n",
    "#     end=end,\n",
    "#     in_universe=True,\n",
    "#     columns=columns\n",
    "# )\n",
    "\n",
    "def add_signals(df: pl.DataFrame, IC=0.05):\n",
    "    return (\n",
    "        df.lazy()\n",
    "        .sort([\"barrid\", \"date\"])\n",
    "        .with_columns([ # Convert nasty percents to nice fractions\n",
    "            pl.col('specific_risk').truediv(100),\n",
    "            pl.col('return').truediv(100),\n",
    "            pl.col('specific_return').truediv(100)\n",
    "        ])\n",
    "        .with_columns(\n",
    "            pl.col('return').log1p().alias('log_return')\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col(\"log_return\")\n",
    "                .rolling_sum(230)\n",
    "                .over(\"barrid\")\n",
    "                .alias(\"momentum_temp\")\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col(\"momentum_temp\").shift(22).over(\"barrid\").alias(\"momentum\")\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col(\"log_return\")\n",
    "                .rolling_sum(22)\n",
    "                .over(\"barrid\")\n",
    "                .alias(\"meanrev_temp\")\n",
    "        )\n",
    "        .with_columns(\n",
    "            (-pl.col(\"meanrev_temp\")).alias(\"meanrev\")\n",
    "        )\n",
    "        .with_columns(\n",
    "            (-pl.col(\"predicted_beta\")).alias(\"bab\")\n",
    "        )\n",
    "        .with_columns([ # Add signal z-scores\n",
    "            ((pl.col(\"momentum\") - pl.col(\"momentum\").mean().over(\"date\")) \n",
    "        / pl.col(\"momentum\").std().over(\"date\")).alias(\"momentum_z\"),\n",
    "            ((pl.col(\"meanrev\") - pl.col(\"meanrev\").mean().over(\"date\")) \n",
    "        / pl.col(\"meanrev\").std().over(\"date\")).alias(\"meanrev_z\"), # Prob should add ddof=1\n",
    "            ((pl.col(\"bab\") - pl.col(\"bab\").mean().over(\"date\")) \n",
    "        / pl.col(\"bab\").std().over(\"date\")).alias(\"bab_z\")\n",
    "        ])\n",
    "        .with_columns([ # Add signal alphas, using alpha = IC * specific_risk * z-score\n",
    "            (IC * pl.col(\"specific_risk\") * pl.col(\"momentum_z\")).alias(\"momentum_alpha\"),\n",
    "            (IC * pl.col(\"specific_risk\") * pl.col(\"meanrev_z\")).alias(\"meanrev_alpha\"),\n",
    "            (IC * pl.col(\"specific_risk\") * pl.col(\"bab_z\")).alias(\"bab_alpha\")\n",
    "        ])\n",
    "        .drop([\"momentum_temp\", \"meanrev_temp\"])\n",
    "        .collect()\n",
    "    )\n",
    "\n",
    "def iter_factor_data(start, end):\n",
    "    \"\"\"\n",
    "    Stream factor-model inputs between two dates (inclusive).\n",
    "\n",
    "    Yields (date, data) tuples where ``data`` is a dict containing:\n",
    "        - ``B``: factor exposure matrix (n_assets x n_factors)\n",
    "        - ``F``: factor covariance matrix (n_factors x n_factors)\n",
    "        - ``D``: specific risk variances (length n_assets)\n",
    "        - ``barrid``: asset identifiers ordered consistently with ``B`` rows\n",
    "    \"\"\"\n",
    "    exposures = (\n",
    "        sfd.load_exposures(start, end, True, [\"date\", \"barrid\"] + factors)\n",
    "        .fill_nan(0)\n",
    "        .fill_null(0)\n",
    "    )\n",
    "    specific_risk = (\n",
    "        sfd.load_assets(start, end, [\"date\", \"barrid\", \"specific_risk\"], in_universe=True)\n",
    "        .fill_nan(0)\n",
    "        .fill_null(0)\n",
    "    )\n",
    "\n",
    "    dates = sorted(exposures.select(\"date\").unique().to_series().to_list())\n",
    "\n",
    "    for date in tqdm(dates, desc=\"Loading factor data\"):\n",
    "        exp_date = exposures.filter(pl.col(\"date\").eq(date)).sort(\"barrid\")\n",
    "        if exp_date.is_empty():\n",
    "            continue\n",
    "\n",
    "        # Align specific risk to exposure ordering\n",
    "        sr_date = (\n",
    "            exp_date.select(\"barrid\")\n",
    "            .join(\n",
    "                specific_risk.filter(pl.col(\"date\").eq(date)).select(\n",
    "                    \"barrid\", \"specific_risk\"\n",
    "                ),\n",
    "                on=\"barrid\",\n",
    "                how=\"left\",\n",
    "            )\n",
    "            .fill_null(0)\n",
    "            .fill_nan(0)\n",
    "            .sort(\"barrid\")\n",
    "        )\n",
    "\n",
    "        barrids = exp_date.select(\"barrid\").to_series().to_list()\n",
    "        B = exp_date.select(factors).to_numpy()\n",
    "        F = (\n",
    "            _construct_factor_covariance_matrix(date)\n",
    "            .fill_nan(0)\n",
    "            .fill_null(0)\n",
    "            .select(factors)\n",
    "            .to_numpy()\n",
    "            / 1e4 / 252\n",
    "        )\n",
    "        D = np.square(sr_date.select(\"specific_risk\").to_numpy().flatten()) / 1e4 / 252\n",
    "\n",
    "        yield date, {\"B\": B, \"F\": F, \"D\": D, \"barrid\": np.array(barrids)}\n",
    "\n",
    "def load_factor_data(start, end):\n",
    "    \"\"\"\n",
    "    Materialize factor-model inputs between two dates (inclusive) into a dict.\n",
    "\n",
    "    This wraps :func:`iter_factor_data` for callers that want everything in memory.\n",
    "    \"\"\"\n",
    "    return {date: data for date, data in iter_factor_data(start, end)}\n",
    "\n",
    "def build_signal_factor_inputs(start, end, signal, df):\n",
    "    \"\"\"\n",
    "    Combine signal alphas with factor inputs for each date.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    start, end : datetime-like\n",
    "        Date range to include (inclusive).\n",
    "    signal : str\n",
    "        Name of the signal; the alpha column is expected to be ``{signal}_alpha``.\n",
    "    df : pl.DataFrame or pl.LazyFrame\n",
    "        Data containing ``date``, ``barrid`` and the signal alpha column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Keys are dates; values are dicts with ``alpha`` (np.ndarray aligned to\n",
    "        the factor exposure ordering) and the ``B``, ``F``, ``D`` matrices from\n",
    "        :func:`load_factor_data`.\n",
    "    \"\"\"\n",
    "    alpha_col = f\"{signal}_alpha\"\n",
    "\n",
    "    if isinstance(df, pl.LazyFrame):\n",
    "        df = df.collect()\n",
    "\n",
    "    if alpha_col not in df.columns:\n",
    "        raise ValueError(f\"Column '{alpha_col}' not found in provided dataframe.\")\n",
    "\n",
    "    filtered = (\n",
    "        df.filter(\n",
    "            (pl.col(\"date\") >= start)\n",
    "            & (pl.col(\"date\") <= end)\n",
    "            & pl.col(alpha_col).is_not_null()\n",
    "        )\n",
    "        .select([\"date\", \"barrid\", alpha_col])\n",
    "    )\n",
    "\n",
    "    alpha_by_date = {}\n",
    "    for frame in filtered.partition_by(\"date\", maintain_order=True):\n",
    "        date_value = frame[\"date\"][0]\n",
    "        alpha_by_date[date_value] = dict(\n",
    "            zip(frame[\"barrid\"].to_list(), frame[alpha_col].to_list())\n",
    "        )\n",
    "\n",
    "    factor_data = load_factor_data(start, end)\n",
    "    combined = {}\n",
    "\n",
    "    for date, data in factor_data.items():\n",
    "        barrids = data.get(\"barrid\")\n",
    "        if barrids is None:\n",
    "            raise ValueError(\"Factor data missing barrid ordering; rerun load_factor_data.\")\n",
    "\n",
    "        alpha_map = alpha_by_date.get(date, {})\n",
    "        alpha_vec = np.array([alpha_map.get(b, 0.0) for b in barrids])\n",
    "\n",
    "        combined[date] = {\n",
    "            \"alpha\": alpha_vec,\n",
    "            \"B\": data[\"B\"],\n",
    "            \"F\": data[\"F\"],\n",
    "            \"D\": data[\"D\"],\n",
    "        }\n",
    "\n",
    "    return combined\n",
    "\n",
    "def iter_factor_mvos(start, end, signal, df, A=None, b=None, L=None, d=None, d_floor=1e-8):\n",
    "    \"\"\"\n",
    "    Stream per-date FactorMVO instances with alphas aligned to factor exposures.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    start, end : datetime-like\n",
    "        Date range to include (inclusive).\n",
    "    signal : str\n",
    "        Signal name; alpha column must be ``{signal}_alpha``.\n",
    "    df : pl.DataFrame or pl.LazyFrame\n",
    "        Source data containing alphas.\n",
    "    A, b, L, d : optional\n",
    "        Constraint matrices/vectors to pass into :class:`FactorMVO`.\n",
    "    d_floor : float\n",
    "        Lower bound for specific risk diagonal entries in the optimizer.\n",
    "\n",
    "    Yields\n",
    "    ------\n",
    "    tuple\n",
    "        (date, FactorMVO) for each available date.\n",
    "    \"\"\"\n",
    "    alpha_col = f\"{signal}_alpha\"\n",
    "\n",
    "    if isinstance(df, pl.LazyFrame):\n",
    "        df = df.collect()\n",
    "\n",
    "    if alpha_col not in df.columns:\n",
    "        raise ValueError(f\"Column '{alpha_col}' not found in provided dataframe.\")\n",
    "\n",
    "    # Keep only relevant slice of alpha data up front\n",
    "    alpha_slice = (\n",
    "        df.filter(\n",
    "            (pl.col(\"date\") >= start)\n",
    "            & (pl.col(\"date\") <= end)\n",
    "            & pl.col(alpha_col).is_not_null()\n",
    "        )\n",
    "        .select([\"date\", \"barrid\", alpha_col])\n",
    "    )\n",
    "\n",
    "    alpha_by_date = {}\n",
    "    for frame in alpha_slice.partition_by(\"date\", maintain_order=True):\n",
    "        date_value = frame[\"date\"][0]\n",
    "        alpha_by_date[date_value] = dict(\n",
    "            zip(frame[\"barrid\"].to_list(), frame[alpha_col].to_list())\n",
    "        )\n",
    "\n",
    "    for date, data in iter_factor_data(start, end):\n",
    "        barrids = data[\"barrid\"]\n",
    "        alpha_map = alpha_by_date.get(date, {})\n",
    "        alpha_vec = np.array([alpha_map.get(b, 0.0) for b in barrids])\n",
    "\n",
    "        yield date, FactorMVO(alpha_vec, data[\"B\"], data[\"F\"], data[\"D\"], A=A, b=b, L=L, d=d, d_floor=d_floor)\n",
    "\n",
    "class FactorMVO:\n",
    "    \"\"\"\n",
    "    Factor-model mean-variance optimizer that applies the factor covariance as a LinearOperator\n",
    "    (no explicit nxn covariance computation).\n",
    "\n",
    "    Objective: maximize alpha^T w - (gamma / 2) * w^T Cov w,  Cov = B F B^T + diag(D)\n",
    "    Constraints: A w = b, optional L w <= d (not implemented yet), or target active risk.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha, B, F, D, A=None, b=None, L=None, d=None, d_floor=1e-8):\n",
    "        self.alpha = alpha          # n\n",
    "        self.B = B                  # n Ã— k\n",
    "        self.F = F                  # k Ã— k\n",
    "        self.D = np.maximum(D, d_floor)  # n, floor to keep H SPD enough for Krylov\n",
    "        self.A = A                  # m Ã— n  (equality constraints, e.g. UnitBeta, ZeroBeta, FullInvestment)\n",
    "        self.b = b                  # m\n",
    "        self.L = L                  # p Ã— n  (inequality constraints, e.g. LongOnly. Must be less than version, hence L)\n",
    "        self.d = d                  # p\n",
    "\n",
    "        self.n = len(alpha)\n",
    "        self.k = F.shape[0]\n",
    "    \n",
    "    def _make_H_operator(self, gamma):\n",
    "        \"\"\"Return LinearOperator for Hessian gamma*Cov without forming Cov.\"\"\"\n",
    "        n, _ = self.B.shape # _ really means k\n",
    "\n",
    "        def matvec(x):\n",
    "            # x: length n\n",
    "            Btx = self.B.T @ x            # R^k\n",
    "            F_Btx = self.F @ Btx         # R^k\n",
    "            B_F_Btx = self.B @ F_Btx  # R^n\n",
    "            return gamma * (B_F_Btx + self.D * x)\n",
    "\n",
    "        return LinearOperator(\n",
    "            shape=(n, n),\n",
    "            matvec=matvec,\n",
    "            dtype=float\n",
    "        )\n",
    "\n",
    "    def _make_KKT_operator(self, gamma):\n",
    "        \"\"\"\n",
    "        KKT matrix:\n",
    "            [ H   A^T ]\n",
    "            [ A    0  ]\n",
    "        implemented as a LinearOperator.\n",
    "        \"\"\"\n",
    "        n = self.B.shape[0]\n",
    "        m = self.A.shape[0]\n",
    "\n",
    "        # Build H as a LinearOperator\n",
    "        H_op = self._make_H_operator(gamma)\n",
    "\n",
    "        def matvec(z):\n",
    "            # z = [x, y]\n",
    "            x = z[:n]\n",
    "            y = z[n:]\n",
    "\n",
    "            top = H_op.matvec(x) + self.A.T @ y\n",
    "            bottom = self.A @ x\n",
    "\n",
    "            return np.concatenate([top, bottom])\n",
    "\n",
    "        return LinearOperator(\n",
    "            shape=(n + m, n + m),\n",
    "            matvec=matvec,\n",
    "            dtype=float\n",
    "        )\n",
    "\n",
    "    def cov_times(self, w):\n",
    "        \"\"\"Compute Cov * w without forming Cov explicitly.\"\"\"\n",
    "        Bw = self.B.T @ w              # k\n",
    "        F_Bw = self.F @ Bw             # k\n",
    "        return self.B @ F_Bw + self.D * w\n",
    "\n",
    "    def risk(self, w):\n",
    "        \"\"\"Compute sqrt( w^T Cov w ).\"\"\"\n",
    "        return np.sqrt(w @ self.cov_times(w))\n",
    "\n",
    "    def kkt_residuals(self, w, gamma):\n",
    "        \"\"\"Return (||A w - b||_2, ||g + A^T lambda||_2) with g = -alpha + gamma*Cov w.\"\"\"\n",
    "        g = -self.alpha + gamma * self.cov_times(w)\n",
    "\n",
    "        if self.A is None:\n",
    "            primal = 0.0\n",
    "            dual = np.linalg.norm(g)\n",
    "            return primal, dual\n",
    "\n",
    "        primal_vec = self.A @ w - self.b\n",
    "        # Solve for lambda in (A A^T) lambda = A (-g) to get best dual residual\n",
    "        ATA = self.A @ self.A.T\n",
    "        rhs = self.A @ (-g)\n",
    "        lam, *_ = np.linalg.lstsq(ATA, rhs, rcond=None)\n",
    "        dual_vec = g + self.A.T @ lam\n",
    "\n",
    "        return np.linalg.norm(primal_vec), np.linalg.norm(dual_vec)\n",
    "\n",
    "    def solve(self, gamma, active_risk_target=None, max_iter=50, tol=1e-8, debug=False):\n",
    "        \"\"\"\n",
    "        Solve:\n",
    "            maximize alpha^T w - (gamma / 2) * w^T Cov w\n",
    "        with constraints.\n",
    "        active_risk_target: impose sqrt(w^T Cov w) = active_risk_target via bisection on gamma.\n",
    "        \"\"\"\n",
    "\n",
    "        # If active_risk_target is given, use the _solve_for_risk version\n",
    "        if active_risk_target is not None:\n",
    "            return self._solve_for_risk(active_risk_target, gamma_init=gamma, debug=debug)\n",
    "\n",
    "        # KKT solve for fixed gamma\n",
    "        return self._solve_fixed_gamma(gamma, max_iter=max_iter, tol=tol, debug=debug)\n",
    "\n",
    "    def _solve_fixed_gamma(self, gamma, max_iter=500, tol=1e-8, debug=False, w0=None):\n",
    "        \"\"\"\n",
    "        Newton solve for fixed gamma with equality constraints via KKT MINRES.\n",
    "        \"\"\"\n",
    "\n",
    "        if debug:\n",
    "            start = perf_counter()\n",
    "            print(f'[INFO] Started optimizer with gamma={gamma}.')\n",
    "\n",
    "        n = self.n\n",
    "        w = np.zeros(n) if w0 is None else w0.copy()\n",
    "\n",
    "        A = self.A\n",
    "        b = self.b\n",
    "        m = 0 if A is None else A.shape[0]\n",
    "\n",
    "        lin_maxiter = max(500, 5 * self.n)\n",
    "\n",
    "        converged = False\n",
    "        # Newton loop\n",
    "        for _ in range(max_iter): # Might want to track and return this\n",
    "\n",
    "            # Gradient: g = - alpha + gamma Cov w   (negative because maximizing)\n",
    "            g = -self.alpha + gamma * self.cov_times(w)\n",
    "\n",
    "            # Hessian operator: H v = gamma Cov v\n",
    "            # We apply Cov v via cov_times.\n",
    "\n",
    "            # Build KKT system:\n",
    "            #\n",
    "            # [ H   A^T ] [ dw ] = - [ g ]\n",
    "            # [ A    0  ] [ dl ]     [ r ]\n",
    "            #\n",
    "            # dw is the primal step; dl (lambda) is the dual step for the equality constraints.\n",
    "            # r = A w - b is the constraint residual.\n",
    "            #\n",
    "            # This is solved with block elimination:\n",
    "            #\n",
    "            # Solve  H dw + A^T dl = -g\n",
    "            #        A dw         = -(A w - b)\n",
    "\n",
    "            if m == 0:\n",
    "                H_op = self._make_H_operator(gamma)\n",
    "                dw, info = minres(H_op, -g, rtol=1e-10, maxiter=lin_maxiter)\n",
    "                if info != 0:\n",
    "                    raise RuntimeError(f'minres did not converge for unconstrained solve (info={info}).')\n",
    "                w += dw\n",
    "\n",
    "                cur_norm = np.linalg.norm(dw)\n",
    "                if debug: print(f'[INFO] Current norm is {cur_norm}.')\n",
    "                if cur_norm < tol:\n",
    "                    converged = True\n",
    "                    break\n",
    "\n",
    "            else:\n",
    "                K = self._make_KKT_operator(gamma)\n",
    "                print(\"K\", K.shape)\n",
    "                print((A @ w - b).shape)\n",
    "                print(g.shape)\n",
    "\n",
    "                rhs = np.concatenate([-g, -(A @ w - b)])\n",
    "                sol, info = minres(K, rhs, rtol=1e-10, maxiter=lin_maxiter)\n",
    "                if info != 0:\n",
    "                    raise RuntimeError(f'minres did not converge for constrained solve (info={info}).')\n",
    "\n",
    "                dw = sol[:n]\n",
    "                w += dw\n",
    "\n",
    "                cur_norm = np.linalg.norm(dw)\n",
    "                if debug: print(f'[INFO] Current norm is {cur_norm}.')\n",
    "                if cur_norm < tol:\n",
    "                    converged = True\n",
    "                    break\n",
    "\n",
    "        if debug:\n",
    "            end = perf_counter()\n",
    "            print(f'[INFO] Optimizer took {(end - start):.4g} seconds to finish.')\n",
    "\n",
    "        if not converged:\n",
    "            print(f\"[WARN] FactorMVO _solve_fixed_gamma did not reach tol={tol}. \"\n",
    "                  f\"Final step norm={cur_norm:.3e}, iter={max_iter}, gamma={gamma}.\")\n",
    "\n",
    "        return w\n",
    "\n",
    "    def _solve_for_risk(self, target, gamma_init, tol=1e-8, debug=False):\n",
    "        \"\"\"\n",
    "        Approximate sqrt(w^T Cov w) = target by bisection on gamma.\n",
    "        \"\"\"\n",
    "        gamma_low = 1e-1\n",
    "        gamma_high = 1e4\n",
    "        gamma = gamma_init\n",
    "\n",
    "        if debug:\n",
    "            start = perf_counter()\n",
    "            print(f'[INFO] Started optimizer with target active risk {target:.4g}.')\n",
    "\n",
    "        w_init = np.zeros(self.n)\n",
    "        reached = False\n",
    "        for i in range(40):\n",
    "            w = self._solve_fixed_gamma(gamma, w0=w_init)\n",
    "            r = self.risk(w)\n",
    "            w_init = w  # warm start the next solve\n",
    "\n",
    "            if np.abs(r - target) < tol:\n",
    "                reached = True\n",
    "                break\n",
    "            elif r < target:\n",
    "                gamma_high = gamma\n",
    "            else:\n",
    "                gamma_low = gamma\n",
    "\n",
    "            gamma = 0.5 * (gamma_low + gamma_high)\n",
    "\n",
    "            if debug: print(f'[INFO] Finished iteration {i} with risk {r}.')\n",
    "\n",
    "        if debug:\n",
    "            end = perf_counter()\n",
    "            print(f'[INFO] Optimizer with arget risk tuning took {(end - start):.4g} seconds to finish.')\n",
    "\n",
    "        if not reached:\n",
    "            print(f\"[WARN] FactorMVO _solve_for_risk did not reach target risk within tol={tol}. \"\n",
    "                  f\"Final risk={r:.3e}, target={target}, last gamma={gamma}.\")\n",
    "\n",
    "        return self._solve_fixed_gamma(gamma, w0=w_init)\n",
    "\n",
    "\n",
    "def task_run_factor_optimization(signals_df: pl.DataFrame, start: dt.date, end: dt.date, zero_beta: bool = False, gamma: float = 1.0):\n",
    "    print(\"Indexing alphas...\")\n",
    "    if zero_beta:\n",
    "        local_df = signals_df.select([\"date\", \"barrid\", \"alpha\", \"predicted_beta\"])\n",
    "        if isinstance(local_df, pl.LazyFrame):\n",
    "            local_df = local_df.collect()\n",
    "            \n",
    "        alpha_map = {}\n",
    "        beta_map = {}\n",
    "        for row in local_df.iter_rows(named=True):\n",
    "            d, b, a, beta = row['date'], row['barrid'], row['alpha'], row['predicted_beta']\n",
    "            if d not in alpha_map: alpha_map[d] = {}\n",
    "            if d not in beta_map: beta_map[d] = {}\n",
    "            alpha_map[d][b] = a\n",
    "            beta_map[d][b] = beta\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for date, data in iter_factor_data(start, end):\n",
    "            valid_barrids = local_df.filter(pl.col(\"date\") == date)[\"barrid\"].to_list()\n",
    "\n",
    "            mask = np.isin(data[\"barrid\"], valid_barrids)\n",
    "            \n",
    "            daily_B = data[\"B\"][mask]\n",
    "            daily_D = data[\"D\"][mask]\n",
    "            daily_barrids = data[\"barrid\"][mask]\n",
    "\n",
    "            daily_F = data[\"F\"]\n",
    "\n",
    "            daily_alphas = alpha_map.get(date, {})\n",
    "            alpha_vec = np.array([daily_alphas.get(barrid, 0.0) for barrid in daily_barrids])\n",
    "            daily_betas = beta_map.get(date, {})\n",
    "            beta_vec = np.array([daily_betas.get(barrid, 0.0) for barrid in daily_barrids]).reshape(1, -1)\n",
    "            daily_b = np.array([[0]])\n",
    "            print(beta_vec.shape)\n",
    "            print(daily_B.shape)\n",
    "            print(alpha_vec.shape)\n",
    "            optimizer = FactorMVO(alpha_vec, daily_B, daily_F, daily_D, beta_vec, daily_b)\n",
    "            try:\n",
    "                weights = optimizer.solve(gamma, tol=1e-8)\n",
    "            except Exception as e:\n",
    "                print(f\"Optimization failed on {date}: {e}\")\n",
    "                continue\n",
    "\n",
    "            day_df = pl.DataFrame({\n",
    "                \"date\": [date] * len(daily_barrids),\n",
    "                \"barrid\": daily_barrids,\n",
    "                \"weight\": weights\n",
    "            }, schema={\n",
    "                \"date\": pl.Date, \n",
    "                \"barrid\": pl.Utf8,\n",
    "                \"weight\": pl.Float64\n",
    "            })\n",
    "            \n",
    "            results.append(day_df)\n",
    "\n",
    "        return pl.concat(results)\n",
    "    local_df = signals_df.select([\"date\", \"barrid\", \"alpha\"])\n",
    "    if isinstance(local_df, pl.LazyFrame):\n",
    "        local_df = local_df.collect()\n",
    "        \n",
    "    alpha_map = {}\n",
    "    for row in local_df.iter_rows(named=True):\n",
    "        d, b, a = row['date'], row['barrid'], row['alpha']\n",
    "        if d not in alpha_map: alpha_map[d] = {}\n",
    "        alpha_map[d][b] = a\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for date, data in iter_factor_data(start, end):\n",
    "        valid_barrids = local_df.filter(pl.col(\"date\") == date)[\"barrid\"].to_list()\n",
    "\n",
    "        mask = np.isin(data[\"barrid\"], valid_barrids)\n",
    "        \n",
    "        daily_B = data[\"B\"][mask]\n",
    "        daily_D = data[\"D\"][mask]\n",
    "        daily_barrids = data[\"barrid\"][mask]\n",
    "\n",
    "        daily_F = data[\"F\"]\n",
    "\n",
    "        daily_alphas = alpha_map.get(date, {})\n",
    "        alpha_vec = np.array([daily_alphas.get(barrid, 0.0) for barrid in daily_barrids])\n",
    "        optimizer = FactorMVO(alpha_vec, daily_B, daily_F, daily_D)\n",
    "        try:\n",
    "            weights = optimizer.solve(gamma, tol=1e-8)\n",
    "        except Exception as e:\n",
    "            print(f\"Optimization failed on {date}: {e}\")\n",
    "            continue\n",
    "\n",
    "        day_df = pl.DataFrame({\n",
    "            \"date\": [date] * len(daily_barrids),\n",
    "            \"barrid\": daily_barrids,\n",
    "            \"weight\": weights\n",
    "        }, schema={\n",
    "            \"date\": pl.Date, \n",
    "            \"barrid\": pl.Utf8,\n",
    "            \"weight\": pl.Float64\n",
    "        })\n",
    "        \n",
    "        results.append(day_df)\n",
    "\n",
    "    return pl.concat(results)\n",
    "\n",
    "signals = pl.read_parquet(\"signals.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b9b1ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
